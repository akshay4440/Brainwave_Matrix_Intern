{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "443c62fc-203e-4be7-9a18-979143d9ac39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref                                                          title                                              size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
      "-----------------------------------------------------------  ------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
      "asinow/car-price-dataset                                     Car Price Dataset                                 135KB  2025-01-26 19:53:28           5706         73  1.0              \n",
      "anandshaw2001/netflix-movies-and-tv-shows                    Netflix Movies and TV Shows                         1MB  2025-01-03 10:33:01          15857        420  1.0              \n",
      "andrexibiza/grocery-sales-dataset                            Grocery Sales Database                            223MB  2025-01-31 19:04:00           1549         32  1.0              \n",
      "ashaychoudhary/diabetes-prediction-in-america-dataset        Diabetes Prediction in America Dataset              2MB  2025-02-04 10:35:49           1381         26  1.0              \n",
      "avis02/crime-data-from-2020-to-present                       Crime Data from 2020 to 2025 LAPD                  49MB  2025-02-05 11:11:01            989         79  1.0              \n",
      "vivekattri/global-ev-charging-stations-dataset               Global EV Charging Stations Dataset               165KB  2025-01-25 17:51:01            875         22  1.0              \n",
      "gazal5277/e-commerce-product-and-customer-dataset            E-Commerce Product and Customer Dataset           103KB  2025-02-06 06:37:32            623         50  1.0              \n",
      "ruchikakumbhar/zomato-dataset                                Zomato Dataset                                      2KB  2025-01-21 03:59:39           2440         33  1.0              \n",
      "ankushpanday1/alzheimers-prediction-dataset-global           Alzheimer’s Prediction Dataset (Global)             1MB  2025-01-30 14:38:39           2208         37  1.0              \n",
      "asinow/laptop-price-dataset                                  Laptop Price Dataset                              181KB  2025-02-01 04:20:16           1426         42  1.0              \n",
      "sachinkumar62/movies-details                                 Movies dataset details                              1MB  2025-02-04 14:32:28           1151         26  1.0              \n",
      "himelsarder/road-accident-survival-dataset                   Road Accident Survival Dataset                      1KB  2025-01-18 06:00:32           2685         28  1.0              \n",
      "ashaychoudhary/anxiety-attack-factors-symptoms-and-severity  Anxiety Attack : Factors, Symptoms, and Severity  244KB  2025-01-19 11:56:21           3992         68  1.0              \n",
      "sgoutami/spotify-streaming-history                           Spotify Streaming History                           6MB  2025-01-25 05:14:49           1168         21  1.0              \n",
      "ankushpanday1/thyroid-cancer-risk-prediction-dataset         Thyroid Cancer Risk Prediction Dataset              4MB  2025-02-03 14:25:31           1016         28  1.0              \n",
      "wlwwwlw/elite-sports-cars-in-data                            Elite Sports Cars in Data                         289KB  2025-02-02 21:23:19           1083         29  1.0              \n",
      "xavierberge/road-accident-dataset                            Road Accident dataset                              47MB  2025-02-05 00:32:37           1468         28  0.9411765        \n",
      "b'ashaychoudhary/advertising-campaign-performance-dataset      \\xf0\\x9f\\x93\\x8a Advertising Campaign Performance Dataset         51KB  2025-02-03 04:49:29            865         30  1.0              '\n",
      "asinow/airplane-price-dataset                                Airplane Price Dataset                            238KB  2025-01-28 18:36:41           2602         40  0.9411765        \n",
      "arshmankhalid/caf-rewards-offer-dataset                      Café Rewards Offer Dataset                          7MB  2025-01-31 16:17:15            669         31  0.88235295       \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set Kaggle API key location\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = \"C:\\\\Users\\\\Sarvadnya\\\\Project ML\\\\.kaggle\"\n",
    "\n",
    "# Verify by listing Kaggle files\n",
    "!kaggle datasets list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aba290db-f85c-4c39-8d9d-b7492cf18d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset extracted successfully!\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Define paths\n",
    "zip_path = r\"C:\\Users\\Sarvadnya\\Project ML\\Fake_News_Dataset.zip\"\n",
    "extract_path = r\"C:\\Users\\Sarvadnya\\Project ML\"\n",
    "\n",
    "# Extract the zip file\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "print(\"Dataset extracted successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6d1734a-adc7-42a3-b91f-7f93c588af19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Files: ['.ipynb_checkpoints', '.kaggle', 'FakeNewsDetection.ipynb', 'fake_and_real_news.csv', 'Fake_News_Dataset.zip']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# List extracted files\n",
    "files = os.listdir(extract_path)\n",
    "print(\"Extracted Files:\", files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bdf8627-75a5-424c-981b-b7cdca307225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top Trump Surrogate BRUTALLY Stabs Him In The...</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. conservative leader optimistic of common ...</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trump proposes U.S. tax overhaul, stirs concer...</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Court Forces Ohio To Allow Millions Of Illega...</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Democrats say Trump agrees to work on immigrat...</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text label\n",
       "0   Top Trump Surrogate BRUTALLY Stabs Him In The...  Fake\n",
       "1  U.S. conservative leader optimistic of common ...  Real\n",
       "2  Trump proposes U.S. tax overhaul, stirs concer...  Real\n",
       "3   Court Forces Ohio To Allow Millions Of Illega...  Fake\n",
       "4  Democrats say Trump agrees to work on immigrat...  Real"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define dataset path\n",
    "dataset_path = r\"C:\\Users\\Sarvadnya\\Project ML\\fake_and_real_news.csv\"\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Display first 5 rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06ff9f60-eaf9-4413-818b-66612a1b94fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9900 entries, 0 to 9899\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Text    9900 non-null   object\n",
      " 1   label   9900 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 154.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2af4fe4-ecba-4a6d-ac42-f5e6c02a9549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top Trump Surrogate BRUTALLY Stabs Him In The...</td>\n",
       "      <td>top trump surrogate brutally stabs him in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. conservative leader optimistic of common ...</td>\n",
       "      <td>us conservative leader optimistic of common gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trump proposes U.S. tax overhaul, stirs concer...</td>\n",
       "      <td>trump proposes us tax overhaul stirs concerns ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Court Forces Ohio To Allow Millions Of Illega...</td>\n",
       "      <td>court forces ohio to allow millions of illega...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Democrats say Trump agrees to work on immigrat...</td>\n",
       "      <td>democrats say trump agrees to work on immigrat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0   Top Trump Surrogate BRUTALLY Stabs Him In The...   \n",
       "1  U.S. conservative leader optimistic of common ...   \n",
       "2  Trump proposes U.S. tax overhaul, stirs concer...   \n",
       "3   Court Forces Ohio To Allow Millions Of Illega...   \n",
       "4  Democrats say Trump agrees to work on immigrat...   \n",
       "\n",
       "                                          clean_text  \n",
       "0   top trump surrogate brutally stabs him in the...  \n",
       "1  us conservative leader optimistic of common gr...  \n",
       "2  trump proposes us tax overhaul stirs concerns ...  \n",
       "3   court forces ohio to allow millions of illega...  \n",
       "4  democrats say trump agrees to work on immigrat...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)  # Remove text in square brackets\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'<.*?>+', '', text)  # Remove HTML tags\n",
    "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\n', '', text)  # Remove newlines\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)  # Remove words containing numbers\n",
    "    return text\n",
    "\n",
    "# Apply text cleaning\n",
    "df['clean_text'] = df['Text'].apply(clean_text)\n",
    "\n",
    "# Show cleaned data\n",
    "df[['Text', 'clean_text']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb1b4c2b-34c5-43ba-85a9-11903903dcf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>label_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fake</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Real</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  label_encoded\n",
       "0  Fake              0\n",
       "1  Real              1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Convert Fake/Real to 0 and 1\n",
    "label_encoder = LabelEncoder()\n",
    "df['label_encoded'] = label_encoder.fit_transform(df['label'])\n",
    "\n",
    "# Display label encoding\n",
    "df[['label', 'label_encoded']].drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e93e1f0-4d86-4690-a437-b6b59b55261f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9900, 5000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "\n",
    "# Transform text data\n",
    "X = tfidf_vectorizer.fit_transform(df['clean_text'])\n",
    "\n",
    "# Target variable\n",
    "y = df['label_encoded']\n",
    "\n",
    "# Check the shape of transformed data\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1013de8-ff1b-4d4a-b81d-ad609554725d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7920, 5000), (1980, 5000))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the shape of the training and testing sets\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a55ec8ec-300b-4ca1-a0a7-329ffcdcc2bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model on the training set\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6732990-0ec2-401b-acba-3cc8a392cfa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9914\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       973\n",
      "           1       0.99      1.00      0.99      1007\n",
      "\n",
      "    accuracy                           0.99      1980\n",
      "   macro avg       0.99      0.99      0.99      1980\n",
      "weighted avg       0.99      0.99      0.99      1980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Display classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "295d8262-f212-4e9c-8206-044255216727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully at C:/Users/Sarvadnya/Project ML/fake_news_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "model_filename = \"C:/Users/Sarvadnya/Project ML/fake_news_model.pkl\"\n",
    "joblib.dump(model, model_filename)\n",
    "\n",
    "print(f\"Model saved successfully at {model_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffd7ff43-ca9e-4971-923a-8c12b4b6cab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flask\n",
      "  Downloading flask-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: joblib in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.3)\n",
      "Collecting Werkzeug>=3.1 (from flask)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from flask) (3.1.5)\n",
      "Collecting itsdangerous>=2.2 (from flask)\n",
      "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from flask) (8.1.8)\n",
      "Requirement already satisfied: blinker>=1.9 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from flask) (1.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading flask-3.1.0-py3-none-any.whl (102 kB)\n",
      "Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Installing collected packages: Werkzeug, itsdangerous, flask\n",
      "Successfully installed Werkzeug-3.1.3 flask-3.1.0 itsdangerous-2.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install flask joblib numpy pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f16de98-48e8-4055-9a67-d0cd4c519427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create a TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Train on sample data (replace this with actual training data if needed)\n",
    "sample_texts = [\"Fake news example\", \"Real news example\"]\n",
    "vectorizer.fit(sample_texts)\n",
    "\n",
    "# Save the vectorizer\n",
    "joblib.dump(vectorizer, \"C:/Users/Sarvadnya/Project ML/tfidf_vectorizer.pkl\")\n",
    "\n",
    "print(\"Vectorizer saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e3e0297-5bb0-4459-a303-a33efed8385e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'title'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'title'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfake_and_real_news.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Combine title and text for better results\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtitle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Split into train and test sets\u001b[39;00m\n\u001b[0;32m     14\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m], df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m], test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'title'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"fake_and_real_news.csv\")\n",
    "\n",
    "# Combine title and text for better results\n",
    "df['content'] = df['title'] + \" \" + df['text']\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['content'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Save the model and vectorizer\n",
    "with open(\"fake_news_model.pkl\", \"wb\") as model_file:\n",
    "    pickle.dump(model, model_file)\n",
    "\n",
    "with open(\"tfidf_vectorizer.pkl\", \"wb\") as vectorizer_file:\n",
    "    pickle.dump(vectorizer, vectorizer_file)\n",
    "\n",
    "print(\"✅ Model and vectorizer saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92f66bb5-96f7-416b-b9cb-323fd966df56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text label\n",
      "0   Top Trump Surrogate BRUTALLY Stabs Him In The...  Fake\n",
      "1  U.S. conservative leader optimistic of common ...  Real\n",
      "2  Trump proposes U.S. tax overhaul, stirs concer...  Real\n",
      "3   Court Forces Ohio To Allow Millions Of Illega...  Fake\n",
      "4  Democrats say Trump agrees to work on immigrat...  Real\n",
      "\n",
      "Column Names: Index(['Text', 'label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"fake_and_real_news.csv\")\n",
    "\n",
    "# Show the first few rows and column names\n",
    "print(df.head())\n",
    "print(\"\\nColumn Names:\", df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "106de58a-fbc3-4677-a5c0-f5bc3dad5109",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'] = df['Text']  # Use only the 'Text' column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31dbb011-b7f6-495f-97dc-281c0b2f13ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text label  \\\n",
      "0   Top Trump Surrogate BRUTALLY Stabs Him In The...  Fake   \n",
      "1  U.S. conservative leader optimistic of common ...  Real   \n",
      "2  Trump proposes U.S. tax overhaul, stirs concer...  Real   \n",
      "3   Court Forces Ohio To Allow Millions Of Illega...  Fake   \n",
      "4  Democrats say Trump agrees to work on immigrat...  Real   \n",
      "\n",
      "                                             content  \n",
      "0   Top Trump Surrogate BRUTALLY Stabs Him In The...  \n",
      "1  U.S. conservative leader optimistic of common ...  \n",
      "2  Trump proposes U.S. tax overhaul, stirs concer...  \n",
      "3   Court Forces Ohio To Allow Millions Of Illega...  \n",
      "4  Democrats say Trump agrees to work on immigrat...  \n",
      "\n",
      "Column Names: Index(['Text', 'label', 'content'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.head())  # Show the first few rows\n",
    "print(\"\\nColumn Names:\", df.columns)  # Show all column names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52f3481f-dce0-4a0c-9f78-48ef70f74192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  label                                            content\n",
      "0  Fake   Top Trump Surrogate BRUTALLY Stabs Him In The...\n",
      "1  Real  U.S. conservative leader optimistic of common ...\n",
      "2  Real  Trump proposes U.S. tax overhaul, stirs concer...\n",
      "3  Fake   Court Forces Ohio To Allow Millions Of Illega...\n",
      "4  Real  Democrats say Trump agrees to work on immigrat...\n"
     ]
    }
   ],
   "source": [
    "df.drop(columns=['Text'], inplace=True)\n",
    "print(df.head())  # Verify the changes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e6759b0-6982-43bf-93c7-62eb0f726cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining rows after dropping missing values: 9900\n"
     ]
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "print(\"Remaining rows after dropping missing values:\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb82b73b-3a5e-46db-a514-d9d0679f5ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'] = df['content'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52ee9b75-03b7-4795-86e0-ad374d85c598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "df['content'] = df['content'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29d99fa1-61d5-4222-bf6e-54ab1d3d7cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Sarvadnya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "df['content'] = df['content'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f0785c2-c2a2-48cf-968d-d27dbc2a7723",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#': Expected package name at the start of dependency specifier\n",
      "    #\n",
      "    ^\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn   # Run this only if scikit-learn is not installed\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6fffa31b-8a2c-4b86-9485-340077944c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (2.2.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30f7b79f-cd55-4e0a-ab2c-64e3de6189a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # Use top 5000 words\n",
    "X = vectorizer.fit_transform(df['content']).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29c7cfce-9d37-45ec-8103-6922a0e9702d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9900, 5000)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)  # Check dimensions of transformed data\n",
    "print(X[:5])    # Print first 5 rows of vectorized data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0a0dc2c4-0fac-47dc-bad4-9d2748a04ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Shape: (7920, 5000)\n",
      "Test Set Shape: (1980, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df['label']  # Target labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Train Set Shape:\", X_train.shape)\n",
    "print(\"Test Set Shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2827948f-bdc0-4d90-bc5a-1ee97359dce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training completed!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model training completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "24ba2d30-7e3e-44d9-9ba3-584b92f34a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9955\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake       1.00      0.99      1.00       973\n",
      "        Real       0.99      1.00      1.00      1007\n",
      "\n",
      "    accuracy                           1.00      1980\n",
      "   macro avg       1.00      1.00      1.00      1980\n",
      "weighted avg       1.00      1.00      1.00      1980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b0cade8f-23ee-43bc-994b-c3fb9c8cea80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and vectorizer saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(model, \"C:/Users/Sarvadnya/Project ML/fake_news_model.pkl\")\n",
    "\n",
    "# Save the TF-IDF vectorizer\n",
    "joblib.dump(vectorizer, \"C:/Users/Sarvadnya/Project ML/tfidf_vectorizer.pkl\")\n",
    "\n",
    "print(\"Model and vectorizer saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d9496213-1694-4277-bb2b-27287eb8a8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and vectorizer saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(model, \"C:/Users/Sarvadnya/Project ML/fake_news_model.pkl\")\n",
    "\n",
    "# Save the TF-IDF vectorizer\n",
    "joblib.dump(vectorizer, \"C:/Users/Sarvadnya/Project ML/tfidf_vectorizer.pkl\")\n",
    "\n",
    "print(\"Model and vectorizer saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4b860615-69b1-4d25-af75-5a2877a1b654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import sklearn\n",
    "import flask  # If using Flask for deployment\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4edf41b5-2f0e-4e29-93d7-76b00ceed63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Output: ['Fake']\n"
     ]
    }
   ],
   "source": [
    "# Load saved model\n",
    "loaded_model = joblib.load(\"C:/Users/Sarvadnya/Project ML/fake_news_model.pkl\")\n",
    "\n",
    "# Load saved vectorizer\n",
    "loaded_vectorizer = joblib.load(\"C:/Users/Sarvadnya/Project ML/tfidf_vectorizer.pkl\")\n",
    "\n",
    "# Test prediction\n",
    "sample_text = [\"This is a test news article\"]\n",
    "sample_vectorized = loaded_vectorizer.transform(sample_text)\n",
    "prediction = loaded_model.predict(sample_vectorized)\n",
    "\n",
    "print(\"Prediction Output:\", prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0b950854-ff24-4741-b4a8-64b118a65552",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = [\"Breaking news: AI detects fake articles!\"]\n",
    "sample_vectorized = loaded_vectorizer.transform(sample_text)\n",
    "prediction = loaded_model.predict(sample_vectorized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "afc9fa7e-ed52-4f42-b3b9-13b05d1fb3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlitNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached streamlit-1.42.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (5.5.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (8.1.8)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (2.2.2)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (2.2.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (11.1.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (5.29.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (19.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (13.9.4)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (9.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (4.12.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (3.1.44)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (6.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.5)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from altair<6,>=4.0->streamlit) (1.25.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.19.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sarvadnya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Using cached streamlit-1.42.0-py2.py3-none-any.whl (9.6 MB)\n",
      "Installing collected packages: streamlit\n",
      "Successfully installed streamlit-1.42.0\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "be3c5d73-0ce3-46f2-ba86-ed24616e637d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Vectorizer saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the vectorizer again\n",
    "vectorizer_path = \"C:/Users/Sarvadnya/Project ML/tfidf_vectorizer.pkl\"\n",
    "with open(vectorizer_path, \"wb\") as file:\n",
    "    pickle.dump(vectorizer, file)\n",
    "\n",
    "print(\"✅ Vectorizer saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d0ed8881-4727-46fe-a4be-e3c75ef089b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚨 Error loading model: [Errno 2] No such file or directory: 'C:/Users/Sarvadnya/Project ML/model.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Define the path where the model.pkl file is stored\n",
    "model_path = \"C:/Users/Sarvadnya/Project ML/model.pkl\"\n",
    "\n",
    "try:\n",
    "    # Try loading the model\n",
    "    with open(model_path, \"rb\") as file:\n",
    "        model = pickle.load(file)\n",
    "    \n",
    "    # Print model type to verify it is a classifier\n",
    "    print(\"✅ Model Loaded Successfully:\", type(model))\n",
    "\n",
    "    # Check if model has a .predict() method\n",
    "    if hasattr(model, 'predict'):\n",
    "        print(\"✅ Model is ready for predictions!\")\n",
    "    else:\n",
    "        print(\"❌ Model does NOT have a 'predict()' method. Resave the correct model.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"🚨 Error loading model:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "128e531d-5600-4e83-aeb6-af28ba916357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved successfully at: C:/Users/Sarvadnya/Project ML/model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Define the correct save path\n",
    "model_path = \"C:/Users/Sarvadnya/Project ML/model.pkl\"\n",
    "\n",
    "# Save the trained model again\n",
    "with open(model_path, \"wb\") as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "print(\"✅ Model saved successfully at:\", model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7d894707-0e7b-4bb0-8fbc-05eaa8006700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model Loaded Successfully: <class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "✅ Model is ready for predictions!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Define the path where the model.pkl file is stored\n",
    "model_path = \"C:/Users/Sarvadnya/Project ML/model.pkl\"\n",
    "\n",
    "try:\n",
    "    # Try loading the model\n",
    "    with open(model_path, \"rb\") as file:\n",
    "        model = pickle.load(file)\n",
    "    \n",
    "    # Print model type to verify it is a classifier\n",
    "    print(\"✅ Model Loaded Successfully:\", type(model))\n",
    "\n",
    "    # Check if model has a .predict() method\n",
    "    if hasattr(model, 'predict'):\n",
    "        print(\"✅ Model is ready for predictions!\")\n",
    "    else:\n",
    "        print(\"❌ Model does NOT have a 'predict()' method. Resave the correct model.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"🚨 Error loading model:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ccabc2fe-fff8-4019-ac94-9946e19156ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved successfully at: C:/Users/Sarvadnya/Project ML/model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Define the correct save path\n",
    "model_path = \"C:/Users/Sarvadnya/Project ML/model.pkl\"\n",
    "\n",
    "# Save the trained model again\n",
    "with open(model_path, \"wb\") as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "print(\"✅ Model saved successfully at:\", model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d2be64a9-9ca8-4da3-989f-e300235f0d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the model\n",
    "model_path = \"C:/Users/Sarvadnya/Project ML/model.pkl\"\n",
    "model = pickle.load(open(model_path, \"rb\"))\n",
    "\n",
    "# Check the type of model\n",
    "print(type(model))  # It should NOT be <class 'numpy.ndarray'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8597eb86-ea8a-4d34-b7a1-c1ac5eca7731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved successfully at: C:/Users/Sarvadnya/Project ML/model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Define the correct file path\n",
    "model_path = \"C:/Users/Sarvadnya/Project ML/model.pkl\"\n",
    "\n",
    "# Save the trained model\n",
    "pickle.dump(model, open(model_path, \"wb\"))\n",
    "\n",
    "print(\"✅ Model saved successfully at:\", model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1f2be81c-9f1f-4d77-a258-28ace7b0bffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "loaded_model = pickle.load(open(model_path, \"rb\"))\n",
    "\n",
    "# Check the type of model\n",
    "print(type(loaded_model))  # Expected output: <class 'sklearn.linear_model._logistic.LogisticRegression'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bd2a1576-5d45-458c-b45a-30466819a019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained model\n",
    "with open(\"C:/Users/Sarvadnya/Project ML/model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "print(\"Model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ec006296-cc9b-4f00-bb8a-955f84c256e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the saved model\n",
    "with open(\"C:/Users/Sarvadnya/Project ML/model.pkl\", \"rb\") as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "print(\"Model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9ce4a5c3-725a-4fe7-9bfd-9a20baebe527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the saved model\n",
    "with open(\"C:/Users/Sarvadnya/Project ML/model.pkl\", \"rb\") as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "print(\"Model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b628a9ef-76d7-48a8-9217-5604715d9cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Fake\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the model\n",
    "with open(\"C:/Users/Sarvadnya/Project ML/model.pkl\", \"rb\") as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "# Load the vectorizer\n",
    "with open(\"C:/Users/Sarvadnya/Project ML/tfidf_vectorizer.pkl\", \"rb\") as file:\n",
    "    vectorizer = pickle.load(file)\n",
    "\n",
    "# Sample text input\n",
    "input_text = \"Breaking News: Stock market crashes due to economic downturn!\"\n",
    "\n",
    "# Transform the input\n",
    "transformed_text = vectorizer.transform([input_text])\n",
    "\n",
    "# Make the prediction\n",
    "prediction = model.predict(transformed_text)[0]\n",
    "\n",
    "print(\"Prediction:\", prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c467c3a2-c32e-4d1f-a0ef-daf89f6a18d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained model\n",
    "with open(\"C:/Users/Sarvadnya/Project ML/model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "print(\"Model saved successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9df1e6bb-c294-4e59-ba91-8a74180642bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the saved model\n",
    "with open(\"C:/Users/Sarvadnya/Project ML/model.pkl\", \"rb\") as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "print(\"Model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "49f57bc3-2d64-4f32-965e-1b756c89c817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load model\n",
    "with open(\"C:/Users/Sarvadnya/Project ML/model.pkl\", \"rb\") as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "print(type(model))  # Check the type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f0f22ed9-ad0f-4e36-a5d3-7d815b87aa2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9954545454545455\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fake       1.00      0.99      1.00       973\n",
      "        Real       0.99      1.00      1.00      1007\n",
      "\n",
      "    accuracy                           1.00      1980\n",
      "   macro avg       1.00      1.00      1.00      1980\n",
      "weighted avg       1.00      1.00      1.00      1980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bb6180cc-15bd-469f-9600-4ceb0c70ae7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for Fake News sample: ['Fake']\n"
     ]
    }
   ],
   "source": [
    "# Test with a known Fake news sample\n",
    "fake_news = [\"Breaking: Celebrity endorses unverified product with false claims!\"]\n",
    "transformed_fake = vectorizer.transform(fake_news)\n",
    "pred_fake = model.predict(transformed_fake)\n",
    "\n",
    "print(\"Prediction for Fake News sample:\", pred_fake)  # Expected: 0 (Fake)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f380010-4809-4764-8186-9b5fcc54cef8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
